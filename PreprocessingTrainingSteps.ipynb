{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "095e249d-2fc7-446d-901a-c2aef4c3dfb1",
   "metadata": {},
   "source": [
    "# Dataset link\n",
    "https://www.kaggle.com/datasets/vencerlanz09/sea-animals-image-dataste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399e9ea-5ed6-4aae-b0f0-54340442d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import models, transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c3db47-2097-4698-9ba4-dab590aca998",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac444bd-bc34-413c-a073-d83e6ef320c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process each image and convert to a feature vector\n",
    "def process_image(image_path):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path).convert('RGB')  # Convert to RGB if grayscale\n",
    "    # Apply the preprocessing transform\n",
    "    image = preprocess_transform(image)\n",
    "    # Convert to a numpy array\n",
    "    return image.numpy()\n",
    "\n",
    "# Function to get class label based on the directory name\n",
    "def get_class_label(folder_name):\n",
    "    if folder_name in class_1_labels:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Main function to preprocess the dataset\n",
    "def preprocess_dataset(base_directory):\n",
    "    class_0_data = []\n",
    "    class_1_data = []\n",
    "\n",
    "    # Traverse the directory\n",
    "    for folder in os.listdir(base_directory):\n",
    "        folder_path = os.path.join(base_directory, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            class_label = get_class_label(folder)  # Determine if it's class_0 or class_1\n",
    "            \n",
    "            # Loop over each image in the folder\n",
    "            for filename in os.listdir(folder_path):\n",
    "                print(filename)\n",
    "                if filename.endswith(\".jpg\"):  # Only process .jpg images\n",
    "                    image_path = os.path.join(folder_path, filename)\n",
    "                    image_vector = process_image(image_path)  # Process image into a vector\n",
    "                    \n",
    "                    # Add the label (0 or 1) to the vector\n",
    "                    image_vector = np.append(image_vector, class_label)\n",
    "                    \n",
    "                    # Store the image in the corresponding class array\n",
    "                    if class_label == 0:\n",
    "                        class_0_data.append(image_vector)\n",
    "                    else:\n",
    "                        class_1_data.append(image_vector)\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    class_0_data = np.array(class_0_data)\n",
    "    class_1_data = np.array(class_1_data)\n",
    "    \n",
    "    return class_0_data, class_1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc747c9b-3df1-4b03-b751-aef5104a070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classes that correspond to class_1 and class_0\n",
    "class_1_labels = [\"Sea Urchins\", \"Puffers\", \"Sea Rays\", \"Eel\", \"Otter\"]\n",
    "\n",
    "# Define a transformation to preprocess the image (resize, normalize)\n",
    "preprocess_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet expects 224x224 images\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize as per ResNet\n",
    "])\n",
    "\n",
    "# Base directory of your dataset (modify accordingly)\n",
    "base_directory = \"./datasettoprocess\"\n",
    "\n",
    "# Preprocess the dataset\n",
    "class_0_array, class_1_array = preprocess_dataset(base_directory)\n",
    "\n",
    "# Save the arrays as .npy files for future loading\n",
    "np.save('class_0.npy', class_0_array)\n",
    "np.save('class_1.npy', class_1_array)\n",
    "\n",
    "print(\"Preprocessing complete. Saved class_0.npy and class_1.npy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c9f2e4-63d1-4cae-b9d1-dd3addb9ef60",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067bf9c5-961f-41dc-ace1-bce4fd55b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from .npy files\n",
    "class0 = np.load('class_0.npy')\n",
    "class1 = np.load('class_1.npy')\n",
    "\n",
    "# Ensure the data is in the shape [num_samples, channels, height, width]\n",
    "# Assuming the images are originally in shape [height, width, channels]\n",
    "# Convert to [channels, height, width] and normalize to [0, 1]\n",
    "def preprocess_images(images):\n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        img = Image.fromarray(img)  # Convert to PIL image\n",
    "        img = transforms.Resize((224, 224))(img)  # Resize to (224, 224)\n",
    "        img = transforms.ToTensor()(img)  # Convert to tensor\n",
    "        img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)  # Normalize\n",
    "        processed_images.append(img)\n",
    "    return torch.stack(processed_images)\n",
    "\n",
    "# Combine the arrays and create labels\n",
    "X = np.concatenate([class0, class1], axis=0)\n",
    "y = np.concatenate([np.zeros(len(class0)), np.ones(len(class1))])\n",
    "\n",
    "# Preprocess images\n",
    "X_tensor = preprocess_images(X)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Split data into train, validation, and test sets (80%, 10%, 10%)\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the model\n",
    "class CustomResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomResNet50, self).__init__()\n",
    "        self.resnet50 = models.resnet50(pretrained=True)\n",
    "        # Replace the final fully connected layer with a new one for binary classification\n",
    "        num_features = self.resnet50.fc.in_features\n",
    "        self.resnet50.fc = nn.Linear(num_features, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)\n",
    "\n",
    "model = CustomResNet50()\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    train_losses.append(epoch_loss)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        val_loss = val_running_loss / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Save the model with the best validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "# Testing\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure()\n",
    "plt.plot(range(num_epochs), train_losses, label='Training Loss')\n",
    "plt.plot(range(num_epochs), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
